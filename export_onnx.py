import cv2
import torch
import torch.onnx
import onnx
from models import AutoDriveNet

print("ğŸš€ ä»£ç å¼€å§‹è¿è¡Œ...")

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… è®¾å¤‡è®¾ç½®å®Œæˆ: {device}")

# åŠ è½½è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹
checkpoint_path = "./ve.pth"
print(f"ğŸ” æ­£åœ¨åŠ è½½æ¨¡å‹: {checkpoint_path}")

try:
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model = AutoDriveNet().to(device)
    model.load_state_dict(checkpoint['model'], strict=False)
    model.eval()
    print("âœ… PyTorch æ¨¡å‹åŠ è½½å®Œæˆ")
except Exception as e:
    print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    exit()

# åŠ è½½æµ‹è¯•å›¾åƒ
img_path = "./results/2.jpg"
print(f"ğŸ” æ­£åœ¨åŠ è½½æµ‹è¯•å›¾ç‰‡: {img_path}")

try:
    img = cv2.imread(img_path)
    img = cv2.resize(img, (160, 120))  # å‡è®¾è¾“å…¥å¤§å°æ˜¯ 160x120
    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    print("âœ… æµ‹è¯•å›¾ç‰‡åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âŒ è¯»å–å›¾ç‰‡å¤±è´¥: {e}")
    exit()

# é¢„å¤„ç†
try:
    img = torch.from_numpy(img.copy()).float() / 255.0
    img = img.permute(2, 0, 1).unsqueeze(0).to(device)  # (B, C, H, W)
    print("âœ… é¢„å¤„ç†å®Œæˆ")
except Exception as e:
    print(f"âŒ é¢„å¤„ç†å¤±è´¥: {e}")
    exit()

# å¯¼å‡º ONNX
onnx_path = "results/ve.onnx"
print(f"ğŸ” å¼€å§‹å¯¼å‡º ONNX: {onnx_path}")

try:
    torch.onnx.export(
        model, img, onnx_path,
        export_params=True,
        opset_version=11,  # ONNX ç‰ˆæœ¬
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
    )
    print(f"âœ… ONNX æ¨¡å‹å·²ä¿å­˜åˆ° {onnx_path}")
except Exception as e:
    print(f"âŒ ONNX å¯¼å‡ºå¤±è´¥: {e}")
